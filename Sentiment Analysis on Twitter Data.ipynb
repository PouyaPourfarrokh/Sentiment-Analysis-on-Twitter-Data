{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-19 18:49:31.039112: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pouyasmac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/pouyasmac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Used Packages\n",
    "# Used Packages\n",
    "import pandas as pd         # For data manipulation\n",
    "%pip install  -q numpy\n",
    "%pip install -q tensorflow\n",
    "\n",
    "# Ensure numpy is installed before importing\n",
    "import numpy as np          # For numerical computations\n",
    "import matplotlib.pyplot as plt  # For data visualization\n",
    "import seaborn as sns       # For enhanced visualizations\n",
    "from nltk.corpus import stopwords  # For stopword removal\n",
    "from nltk.tokenize import word_tokenize  # For tokenization\n",
    "import nltk                 # For text processing tools\n",
    "from sklearn.model_selection import train_test_split  # For splitting datasets\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score  # For evaluation\n",
    "from gensim.models import Word2Vec  # For word embeddings\n",
    "from tensorflow.keras.models import Sequential  # For building neural networks\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM  # For model layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # For text tokenization\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences  # For sequence padding\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset_path = 'data/sentiment140.csv'  # Adjust the path as necessary\n",
    "columns = ['sentiment', 'id', 'date', 'query', 'user', 'text']  # Column names for the dataset\n",
    "df = pd.read_csv(dataset_path, encoding='latin1', names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599990</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579249</td>\n",
       "      <td>Tue Jun 16 08:38:59 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>razzberry5594</td>\n",
       "      <td>WOOOOO! Xbox is back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599991</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579284</td>\n",
       "      <td>Tue Jun 16 08:38:59 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AgustinaP</td>\n",
       "      <td>@rmedina @LaTati Mmmm  That sounds absolutely ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599992</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579434</td>\n",
       "      <td>Tue Jun 16 08:39:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>sdancingsteph</td>\n",
       "      <td>ReCoVeRiNg FrOm ThE lOnG wEeKeNd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599993</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579477</td>\n",
       "      <td>Tue Jun 16 08:39:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ChloeAmisha</td>\n",
       "      <td>@SCOOBY_GRITBOYS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599994</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579489</td>\n",
       "      <td>Tue Jun 16 08:39:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>EvolveTom</td>\n",
       "      <td>@Cliff_Forster Yeah, that does work better tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599995 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment          id                          date     query  \\\n",
       "0                0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1                0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2                0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3                0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4                0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...            ...         ...                           ...       ...   \n",
       "1599990          4  2193579249  Tue Jun 16 08:38:59 PDT 2009  NO_QUERY   \n",
       "1599991          4  2193579284  Tue Jun 16 08:38:59 PDT 2009  NO_QUERY   \n",
       "1599992          4  2193579434  Tue Jun 16 08:39:00 PDT 2009  NO_QUERY   \n",
       "1599993          4  2193579477  Tue Jun 16 08:39:00 PDT 2009  NO_QUERY   \n",
       "1599994          4  2193579489  Tue Jun 16 08:39:00 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                               text  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599990    razzberry5594                              WOOOOO! Xbox is back   \n",
       "1599991        AgustinaP  @rmedina @LaTati Mmmm  That sounds absolutely ...  \n",
       "1599992    sdancingsteph                  ReCoVeRiNg FrOm ThE lOnG wEeKeNd   \n",
       "1599993      ChloeAmisha                                  @SCOOBY_GRITBOYS   \n",
       "1599994        EvolveTom  @Cliff_Forster Yeah, that does work better tha...  \n",
       "\n",
       "[1599995 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned Dataset Preview:\n",
      "  sentiment                                               text\n",
      "0  negative  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1  negative  is upset that he can't update his Facebook by ...\n",
      "2  negative  @Kenichan I dived many times for the ball. Man...\n",
      "3  negative    my whole body feels itchy and like its on fire \n",
      "4  negative  @nationwideclass no, it's not behaving at all....\n"
     ]
    }
   ],
   "source": [
    "# Keep only relevant columns\n",
    "df = df[['sentiment', 'text']]\n",
    "\n",
    "# Map sentiment values: 0 = negative, 2 = neutral, 4 = positive\n",
    "df['sentiment'] = df['sentiment'].map({0: 'negative', 2: 'neutral', 4: 'positive'})\n",
    "\n",
    "# Display the updated dataset\n",
    "print(\"\\nCleaned Dataset Preview:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Summary:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count    Dtype \n",
      "---  ------     --------------    ----- \n",
      " 0   sentiment  1600000 non-null  object\n",
      " 1   text       1600000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 24.4+ MB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "sentiment    0\n",
      "text         0\n",
      "dtype: int64\n",
      "\n",
      "Class Distribution:\n",
      "sentiment\n",
      "negative    800000\n",
      "positive    800000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dataset summary\n",
    "print(\"\\nDataset Summary:\")\n",
    "print(df.info())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df['sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
