{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/pouyasmac/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/pouyasmac/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Used Packages\n",
    "# Used Packages\n",
    "import pandas as pd         # For data manipulation\n",
    "%pip install  -q numpy\n",
    "%pip install -q tensorflow\n",
    "\n",
    "# Ensure numpy is installed before importing\n",
    "import numpy as np          # For numerical computations\n",
    "import matplotlib.pyplot as plt  # For data visualization\n",
    "import seaborn as sns       # For enhanced visualizations\n",
    "from nltk.corpus import stopwords  # For stopword removal\n",
    "from nltk.tokenize import word_tokenize  # For tokenization\n",
    "# from nltk.tokenize import word_tokenize\n",
    "import nltk                 # For text processing tools\n",
    "from sklearn.model_selection import train_test_split  # For splitting datasets\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score  # For evaluation\n",
    "from gensim.models import Word2Vec  # For word embeddings\n",
    "from tensorflow.keras.models import Sequential  # For building neural networks\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM  # For model layers\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  # For text tokenization\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences  # For sequence padding\n",
    "\n",
    "import re\n",
    "\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset_path = 'data/sentiment140.csv'  # Adjust the path as necessary\n",
    "columns = ['sentiment', 'id', 'date', 'query', 'user', 'text']  # Column names for the dataset\n",
    "df = pd.read_csv(dataset_path, encoding='latin1', names=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>query</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599990</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579249</td>\n",
       "      <td>Tue Jun 16 08:38:59 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>razzberry5594</td>\n",
       "      <td>WOOOOO! Xbox is back</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599991</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579284</td>\n",
       "      <td>Tue Jun 16 08:38:59 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AgustinaP</td>\n",
       "      <td>@rmedina @LaTati Mmmm  That sounds absolutely ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599992</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579434</td>\n",
       "      <td>Tue Jun 16 08:39:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>sdancingsteph</td>\n",
       "      <td>ReCoVeRiNg FrOm ThE lOnG wEeKeNd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599993</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579477</td>\n",
       "      <td>Tue Jun 16 08:39:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ChloeAmisha</td>\n",
       "      <td>@SCOOBY_GRITBOYS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599994</th>\n",
       "      <td>4</td>\n",
       "      <td>2193579489</td>\n",
       "      <td>Tue Jun 16 08:39:00 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>EvolveTom</td>\n",
       "      <td>@Cliff_Forster Yeah, that does work better tha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599995 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment          id                          date     query  \\\n",
       "0                0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1                0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2                0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3                0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4                0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...            ...         ...                           ...       ...   \n",
       "1599990          4  2193579249  Tue Jun 16 08:38:59 PDT 2009  NO_QUERY   \n",
       "1599991          4  2193579284  Tue Jun 16 08:38:59 PDT 2009  NO_QUERY   \n",
       "1599992          4  2193579434  Tue Jun 16 08:39:00 PDT 2009  NO_QUERY   \n",
       "1599993          4  2193579477  Tue Jun 16 08:39:00 PDT 2009  NO_QUERY   \n",
       "1599994          4  2193579489  Tue Jun 16 08:39:00 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                               text  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599990    razzberry5594                              WOOOOO! Xbox is back   \n",
       "1599991        AgustinaP  @rmedina @LaTati Mmmm  That sounds absolutely ...  \n",
       "1599992    sdancingsteph                  ReCoVeRiNg FrOm ThE lOnG wEeKeNd   \n",
       "1599993      ChloeAmisha                                  @SCOOBY_GRITBOYS   \n",
       "1599994        EvolveTom  @Cliff_Forster Yeah, that does work better tha...  \n",
       "\n",
       "[1599995 rows x 6 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned Dataset Preview:\n",
      "  sentiment                                               text\n",
      "0  negative  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
      "1  negative  is upset that he can't update his Facebook by ...\n",
      "2  negative  @Kenichan I dived many times for the ball. Man...\n",
      "3  negative    my whole body feels itchy and like its on fire \n",
      "4  negative  @nationwideclass no, it's not behaving at all....\n"
     ]
    }
   ],
   "source": [
    "# Keep only relevant columns\n",
    "df = df[['sentiment', 'text']]\n",
    "\n",
    "# Map sentiment values: 0 = negative, 2 = neutral, 4 = positive\n",
    "df['sentiment'] = df['sentiment'].map({0: 'negative', 2: 'neutral', 4: 'positive'})\n",
    "\n",
    "# Display the updated dataset\n",
    "print(\"\\nCleaned Dataset Preview:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Summary:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1600000 entries, 0 to 1599999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count    Dtype \n",
      "---  ------     --------------    ----- \n",
      " 0   sentiment  1600000 non-null  object\n",
      " 1   text       1600000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 24.4+ MB\n",
      "None\n",
      "\n",
      "Missing Values:\n",
      "sentiment    0\n",
      "text         0\n",
      "dtype: int64\n",
      "\n",
      "Class Distribution:\n",
      "sentiment\n",
      "negative    800000\n",
      "positive    800000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Dataset summary\n",
    "print(\"\\nDataset Summary:\")\n",
    "print(df.info())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass Distribution:\")\n",
    "print(df['sentiment'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Preprocessing function\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)\n",
    "    # Remove mentions (@username)\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove hashtags\n",
    "    text = re.sub(r'#', '', text)\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Dataset Preview:\n",
      "  sentiment                                               text  \\\n",
      "0  negative  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
      "1  negative  is upset that he can't update his Facebook by ...   \n",
      "2  negative  @Kenichan I dived many times for the ball. Man...   \n",
      "3  negative    my whole body feels itchy and like its on fire    \n",
      "4  negative  @nationwideclass no, it's not behaving at all....   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0      thats bummer shoulda got david carr third day  \n",
      "1  upset cant update facebook texting might cry r...  \n",
      "2  dived many times ball managed save rest go bounds  \n",
      "3                   whole body feels itchy like fire  \n",
      "4                           behaving im mad cant see  \n"
     ]
    }
   ],
   "source": [
    "# Apply cleaning function to the text column\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "# Display the first few rows of the cleaned dataset\n",
    "print(\"Cleaned Dataset Preview:\")\n",
    "print(df[['sentiment', 'text', 'cleaned_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  sentiment                                       cleaned_text\n",
      "0  negative      thats bummer shoulda got david carr third day\n",
      "1  negative  upset cant update facebook texting might cry r...\n",
      "2  negative  dived many times ball managed save rest go bounds\n",
      "3  negative                   whole body feels itchy like fire\n",
      "4  negative                           behaving im mad cant see\n",
      "cleaned_text\n",
      "<class 'str'>    1600000\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[['sentiment', 'cleaned_text']].head())\n",
    "print(df['cleaned_text'].apply(type).value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>negative</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "      <td>thats bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "      <td>upset cant update facebook texting might cry r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "      <td>dived many times ball managed save rest go bounds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "      <td>whole body feels itchy like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "      <td>behaving im mad cant see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                                               text  \\\n",
       "0  negative  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
       "1  negative  is upset that he can't update his Facebook by ...   \n",
       "2  negative  @Kenichan I dived many times for the ball. Man...   \n",
       "3  negative    my whole body feels itchy and like its on fire    \n",
       "4  negative  @nationwideclass no, it's not behaving at all....   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0      thats bummer shoulda got david carr third day  \n",
       "1  upset cant update facebook texting might cry r...  \n",
       "2  dived many times ball managed save rest go bounds  \n",
       "3                   whole body feels itchy like fire  \n",
       "4                           behaving im mad cant see  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tokenized Dataset Preview:\n",
      "                                      tokenized_text\n",
      "0  [thats, bummer, shoulda, got, david, carr, thi...\n",
      "1  [upset, cant, update, facebook, texting, might...\n",
      "2  [dived, many, times, ball, managed, save, rest...\n",
      "3            [whole, body, feels, itchy, like, fire]\n",
      "4                     [behaving, im, mad, cant, see]\n"
     ]
    }
   ],
   "source": [
    "# Create an empty column named 'tokenized_text'\n",
    "df['tokenized_text'] = None\n",
    "\n",
    "# Apply split() to the 'cleaned_text' column and store the results in 'tokenized_text'\n",
    "df['tokenized_text'] = df['cleaned_text'].apply(lambda x: x.split() if isinstance(x, str) else [])\n",
    "\n",
    "# Display the first few rows to confirm the tokenization\n",
    "print(\"\\nTokenized Dataset Preview:\")\n",
    "print(df[['sentiment', 'cleaned_text', 'tokenized_text']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded GloVe embeddings.\n"
     ]
    }
   ],
   "source": [
    "# Load GloVe Embeddings\n",
    "import os\n",
    "\n",
    "# Define the path to GloVe embeddings\n",
    "glove_path = 'data/glove.6B.100d.txt'  # Adjust path as needed\n",
    "\n",
    "# Create a dictionary to store GloVe embeddings\n",
    "glove_embeddings = {}\n",
    "\n",
    "# Read the GloVe file\n",
    "with open(glove_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]  # The word\n",
    "        vector = np.array(values[1:], dtype='float32')  # The embedding vector\n",
    "        glove_embeddings[word] = vector\n",
    "\n",
    "print(\"Loaded GloVe embeddings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute the average embedding for a tweet\n",
    "def get_tweet_embedding(tokens, embeddings, dim=100):\n",
    "    valid_vectors = [embeddings[word] for word in tokens if word in embeddings]\n",
    "    if valid_vectors:\n",
    "        return np.mean(valid_vectors, axis=0)  # Average the embeddings\n",
    "    else:\n",
    "        return np.zeros(dim)  # Return a zero vector if no valid words are found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute embeddings for all tweets\n",
    "df['embedding'] = df['tokenized_text'].apply(lambda tokens: get_tweet_embedding(tokens, glove_embeddings))\n",
    "\n",
    "# Convert embeddings into a NumPy array\n",
    "X = np.array(df['embedding'].tolist())  # Features\n",
    "y = df['sentiment']  # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix shape: (1600000, 100)\n"
     ]
    }
   ],
   "source": [
    "print(\"Feature matrix shape:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
